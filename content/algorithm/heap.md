---
title: '堆和堆排序'
date: 2024-07-08T20:43:11+08:00
params:
  math: true
---

堆排序是一种原地的、时间复杂度为$O(n\log n)$的排序算法。

## 堆
堆是一种特殊的树。

+ 堆是一个完全二叉树；
+ 堆中每一个节点的值都必须大于等于（或小于等于）其**子树中每个节点**的值。

堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。

对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。

## 如何实现一个堆
完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。因为我们不需要存储左右子节点的指针，单纯地通过数组的下标，就可以找到一个节点的左右子节点和父节点。

![img.png](/images/algorithm/algo-heap-1.png)

从图中我们可以看到，数组中下标为$i$的节点的左子节点，就是下标为$i*2$的节点，右子节点就是下标为$i*2+1$的节点，父节点就是下标为$\frac{i}{2}$的节点。

如果没有特殊说明，下面都是拿大顶堆来讲解。

1. **往堆中插入一个元素**

如果我们把新插入的元素放到堆的最后，如下图，是不是不符合堆的特性了？于是，我们就需要进行调整，让其重新满足堆的特性，这个过程我们起了一个名字，就叫作堆化（heapify）。

堆化实际上有两种，从下往上和从上往下。这里我先讲从下往上的堆化方法。

![img.png](/images/algorithm/algo-heap-2.png)

堆化非常简单，就是**顺着节点所在的路径，向上或者向下，对比，然后交换**。

我们可以让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足刚说的那种大小关系。

![img.png](/images/algorithm/algo-heap-3.png)

```go
//TODO:CODE
```

2. **删除堆顶元素**

任何节点的值都大于等于（或小于等于）子树节点的值，我们可以发现，堆顶元素存储的就是堆中数据的最大值或者最小值。

假设我们构造的是大顶堆，堆顶元素就是最大的元素。当我们删除堆顶元素之后，就需要把第二大的元素放到堆顶，那第二大元素肯定会出现在左右子节点中。然后我们再迭代地删除第二大节点，以此类推，直到叶子节点被删除。

不过这种方法有点问题，就是最后堆化出来的堆并不满足完全二叉树的特性。

![img.png](/images/algorithm/algo-heap-4.png)

实际上，我们稍微改变一下思路，就可以解决这个问题。如下图。我们**把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程**，直到父子节点之间满足大小关系为止。这就是从上往下的堆化方法。

因为我们移除的是数组中的最后一个元素，而在堆化的过程中，都是交换操作，不会出现数组中的“空洞”，所以这种方法堆化之后的结果，肯定满足完全二叉树的特性。

![img.png](/images/algorithm/algo-heap-5.png)

```go
//TODO:CODE
```

一个包含$n$个节点的完全二叉树，树的高度不会超过$\log_{2}n$。堆化的过程是顺着节点所在路径比较交换的，所以堆化的时间复杂度跟树的高度成正比，也就是$O(\log n)$。插入数据和删除堆顶元素的主要逻辑就是堆化，所以，往堆中插入一个元素和删除堆顶元素的时间复杂度都是$O(\log n)$。

## 堆排序
### 建堆
首先将数组原地建成一个堆。所谓“原地”就是，不借助另一个数组，就在原数组上操作。建堆的过程，有两种思路。

第一种是借助我们前面讲的，在堆中插入一个元素的思路。尽管数组中包含$n$个数据，但是我们可以假设，起初堆中只包含一个数据，就是下标为$1$的数据。然后，我们调用前面讲的插入操作，将下标从$2$到$n$的数据依次插入到堆中。这样我们就将包含$n$个数据的数组，组织成了堆。

第二种实现思路，跟第一种截然相反。第一种建堆思路的处理过程是从前往后处理数组数据，并且每个数据插入堆中时，都是从下往上堆化。而第二种实现思路，是从后往前处理数组，并且每个数据都是从上往下堆化。

下图是第二种实现思路的建堆分解步骤图。因为叶子节点往下堆化只能自己跟自己比较，所以我们直接从第一个非叶子节点开始，依次堆化就行了。

![img.png](/images/algorithm/algo-heap-6.png)

![img.png](/images/algorithm/algo-heap-7.png)

```go
//TODO:CODE
```
在这段代码中，我们对下标从$\frac{n}{2}$ 开始到$1$的数据进行堆化，下标是$\frac{n}{2}+1$到$n$的节点是叶子节点，我们不需要堆化。实际上，对于完全二叉树来说，下标从$\frac{n}{2}+1$到$n$的节点都是叶子节点。

每个节点堆化的时间复杂度是$O(\log n)$，那$\frac{n}{2}+1$个节点堆化的总时间复杂度是不是就是$O(n\log n)$呢？这个答案虽然也没错，但是这个值还是不够精确。实际上，堆排序的建堆过程的时间复杂度是$O(n)$。

因为叶子节点不需要堆化，所以需要堆化的节点从倒数第二层开始。每个节点堆化的过程中，需要比较和交换的节点个数，跟这个节点的高度$k$成正比。

我把每一层的节点个数和对应的高度画了出来。我们只需要将每个节点的高度求和，得出的就是建堆的时间复杂度。

![img.png](/images/algorithm/algo-heap-8.png)

我们将每个非叶子节点的高度求和，就是下面这个公式：

![img.png](/images/algorithm/algo-heap-9.png)

把公式左右都乘以$2$，就得到另一个公式$S2$。我们将$S2$错位对齐，并且用$S2$减去$S1$，可以得到$S$。

![img.png](/images/algorithm/algo-heap-10.png)

$S$的中间部分是一个等比数列，所以最后可以用等比数列的求和公式来计算，最终的结果就是下面图中画的这个样子。

![img.png](/images/algorithm/algo-heap-11.png)

因为$h=\log_{2}n$，代入公式$S$，就能得到$S=O(n)$，所以，建堆的时间复杂度就是$O(n)$。

### 排序
建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。我们把它跟最后一个元素交换，那最大元素就放到了下标为$n$的位置。

这个过程有点类似上面讲的“删除堆顶元素”的操作，当堆顶元素移除之后，我们把下标为$n$的元素放到堆顶，然后再通过堆化的方法，将剩下的$n-1$个元素重新构建成堆。堆化完成之后，我们再取堆顶的元素，放到下标是$n-1$的位置，一直重复这个过程，直到最后堆中只剩下标为$1$的一个元素，排序工作就完成了。

![img.png](/images/algorithm/algo-heap-12.png)

```go
//TODO:CODE
```

整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是$O(n)$，排序过程的时间复杂度是$O(n\log n)$，所以，堆排序整体的时间复杂度是$O(n\log n)$。

**堆排序不是稳定的排序算法**，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。

在前面的讲解以及代码中，我都假设，堆中的数据是从数组下标为1的位置开始存储。那如果从$0$开始存储，实际上处理思路是没有任何变化的，唯一变化的，可能就是，代码实现的时候，计算子节点和父节点的下标的公式改变了。

如果节点的下标是$i$，那左子节点的下标就是$2*i+1$，右子节点的下标就是$2*i+2$，父节点的下标就是$\frac{i-1}{2}$。

## 思考
在实际开发中，为什么快速排序要比堆排序性能好？

第一点，堆排序数据访问的方式没有快速排序友好。

对于快速排序来说，数据是顺序访问的。而对于堆排序来说，数据是跳着访问的。 比如，堆排序中，最重要的一个操作就是数据的堆化。比如下面这个例子，对堆顶节点进行堆化，会依次访问数组下标是$1，2，4，8$的元素，而不是像快速排序那样，局部顺序访问，所以，这样对CPU缓存是不友好的。

![img.png](/images/algorithm/algo-heap-13.png)

第二点，对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。

但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。比如，对于一组已经有序的数据来说，经过建堆之后，数据反而变得更无序了。

![img.png](/images/algorithm/algo-heap-14.png)
